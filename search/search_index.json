{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to HRI Teleoperation Tutorial","text":"<p>If you wish to develop cool algorithm or experiments using our teleoperation platform, you are in the right place!</p>"},{"location":"#code-editor","title":"Code Editor","text":"<p>You will need vscode, so download it and install it before diving in!</p>"},{"location":"#extensions","title":"Extensions","text":"<p>To get the best from VS Code, we suggest that you install the following extensions</p> <ul> <li>C/C++ and Python: fundamental coding languages support (previewing function arguments and a lot more);</li> <li>Remote Development: very useful to work remotely on powerful shared working stations.</li> <li>Container Tools: similarly, but for programming \"virtual machines\".</li> <li>Git Graph: basic software versioning visualization client.</li> </ul>"},{"location":"#github","title":"GitHub","text":"<p>If you don't have a GitHub account yet, you can obtain one, it's free and it's a nice web platform where to host your code. For now you may just want to acknowledge that GitHub hosts your code in form of <code>git</code> repositories, and it's extremely comfortable to track changes on your code.</p> <p>Then you need to setup your pc to be able to access your repositories on GitHub, for instance to download or to sync them whenever needed.</p> <p>Note: The following setup procedure must be repeated for each pc you may want to work on, and of course you need an installation of <code>git</code>.</p>"},{"location":"#ssh-authentication","title":"SSH authentication","text":"<p>So first let's set up a pair of encrypted keys, one for the pc, one for GitHub, so that GitHub knows your pc is allowed to acces your private assets on the cloud. </p> <p>Open a terminal and type</p> <pre><code>ssh-keygen -t ed25519 -C \"your_email@example.com\"\n</code></pre> <p>this will generate the keys. We suggest to leave default path and empty passphrase. Then add them to the authentication agent on your pc</p> LinuxWindows <pre><code>eval \"$(ssh-agent -s)\"\nssh-add ~/.ssh/id_ed25519\n</code></pre> <pre><code>Get-Service -Name ssh-agent | Set-Service -StartupType Manual\nStart-Service ssh-agent\nssh-add c:/Users/YOU/.ssh/id_ed25519\n</code></pre> <p>Then follow this guide to add the public key of the pair in GitHub. </p> <p>Finally test the authentication</p> <pre><code>ssh -T git@github.com\n</code></pre>"},{"location":"#packages-authentication","title":"Packages authentication","text":"<p>Not all assets are hosted on GitHub as repositories, sometimes you stor a large amount of data into packages. Follow Step 1 and Step 2 here.</p>"},{"location":"resources/","title":"Resources","text":""},{"location":"resources/#jacobian-pseudoinverse","title":"Jacobian Pseudoinverse","text":"<p>Let's break down Singular Value Decomposition (SVD) and the pseudoinverse with a focus on the mathematical steps and handling of singularities.</p>"},{"location":"resources/#svd-singular-value-decomposition","title":"SVD: Singular Value Decomposition","text":"<p>Given a real \\(m \\times n\\) matrix \\(A\\), the SVD is:</p> \\[ A = U \\Sigma V^T \\] <p>Where:</p> <ul> <li>\\(U \\in \\mathbb{R}^{m \\times m}\\): orthogonal matrix, \\(U^T U = I_m\\)</li> <li>\\(V \\in \\mathbb{R}^{n \\times n}\\): orthogonal matrix, \\(V^T V = I_n\\)</li> <li>\\(\\Sigma \\in \\mathbb{R}^{m \\times n}\\): diagonal matrix with non-negative real entries \\(\\sigma_1 \\geq \\sigma_2 \\geq \\cdots \\geq \\sigma_r &gt; 0\\), \\(r = \\text{rank}(A)\\)</li> </ul> <p>To compute the singular values and U, V matrices of a matrix \\(A\\), you're performing Singular Value Decomposition (SVD). The SVD of a matrix \\(A \\in \\mathbb{R}^{m \\times n}\\) is:</p> \\[ A = U \\Sigma V^T \\] <p>Where:</p> <ul> <li>\\(U \\in \\mathbb{R}^{m \\times m}\\) is an orthogonal matrix (left singular vectors).</li> <li>\\(\\Sigma \\in \\mathbb{R}^{m \\times n}\\) is a diagonal matrix with non-negative real numbers (singular values).</li> <li>\\(V \\in \\mathbb{R}^{n \\times n}\\) is an orthogonal matrix (right singular vectors).</li> </ul> Mathematical Process <p>You can compute the SVD in the following steps:</p> Compute Eigenvalues and Eigenvectors <ul> <li>Find eigenvalues \\(\\lambda_i\\) and eigenvectors of \\(A^TA\\): these give the right singular vectors \\(v_i\\) (columns of \\(V\\)).</li> <li>Find eigenvalues and eigenvectors of \\(AA^T\\): these give the left singular vectors \\(u_i\\) (columns of \\(U\\)).</li> </ul> Compute Singular Values <ul> <li>Singular values \\(\\sigma_i = \\sqrt{\\lambda_i}\\), where \\(\\lambda_i\\) are the non-zero eigenvalues of \\(A^TA\\) (or \\(AA^T\\)).</li> </ul> Interpretation <ul> <li>Columns of \\(U\\): directions in domain space (input).</li> <li>Columns of \\(V\\): directions in codomain space (output).</li> <li>Singular values \\(\\sigma_i\\): how much stretching happens along each axis.</li> </ul> Structure of $\\Sigma$ \\[ \\Sigma = \\begin{bmatrix} D &amp; 0 \\\\ 0 &amp; 0 \\end{bmatrix}, \\quad D = \\text{diag}(\\sigma_1, \\ldots, \\sigma_r), \\quad \\sigma_i &gt; 0 \\] <p>The zero blocks correspond to singularities\u2014directions in which \\(A\\) loses invertibility.</p>"},{"location":"resources/#moore-penrose-pseudoinverse-a","title":"Moore-Penrose Pseudoinverse \\(A^+\\)","text":"<p>Given \\(A = U \\Sigma V^T\\), the pseudoinverse is:</p> \\[ A^+ = V \\Sigma^+ U^T \\] <p>Where \\(\\Sigma^+ \\in \\mathbb{R}^{n \\times m}\\) is defined by:</p> \\[ \\Sigma^+ = \\begin{bmatrix} D^+ &amp; 0 \\\\ 0 &amp; 0 \\end{bmatrix} \\] <p>And:</p> \\[ D^+ = \\text{diag}\\left(\\frac{1}{\\sigma_1}, \\ldots, \\frac{1}{\\sigma_r}\\right) \\] Behavior at Singularities <ul> <li>If \\(\\sigma_i = 0\\), then \\(\\frac{1}{\\sigma_i}\\) is undefined.</li> <li>The pseudoinverse explicitly sets \\(\\frac{1}{\\sigma_i} = 0\\) when \\(\\sigma_i = 0\\).</li> <li>This truncation is essential for numerical stability and defining the pseudoinverse in non-invertible or rank-deficient cases.</li> </ul> <p>The pseudoinverse is defined via the SVD by inverting only the non-zero singular values. At singularities (zero singular values), the inversion is avoided by setting those components to zero. This yields a well-defined, unique, and stable linear operator even when \\(A\\) is not invertible.</p>"},{"location":"resources/#task-space-control","title":"Task-space control","text":"<p>In robotic control, mapping task-space velocities \\(\\dot{x}\\) to joint-space velocities \\(\\dot{q}\\) using the Jacobian pseudoinverse \\(J^+\\) is a standard approach:</p> \\[ \\dot{q} = J^+ \\dot{x} \\] <p>Now, if we do not properly handle small singular values in the Jacobian\u2019s SVD, catastrophic behavior can result \u2014 both numerically and physically.</p> <p>Let \\(J \\in \\mathbb{R}^{m \\times n}\\) (e.g., end-effector velocity as a function of joint velocity), with SVD:</p> \\[ J = U \\Sigma V^T \\quad \\Rightarrow \\quad J^+ = V \\Sigma^+ U^T \\] <p>Where \\(\\Sigma^+ = \\text{diag}\\left(\\frac{1}{\\sigma_1}, \\ldots, \\frac{1}{\\sigma_r}, 0, \\ldots, 0\\right)\\) in the standard definition. But if you do not truncate, and use:</p> \\[ \\Sigma^+ = \\text{diag}\\left(\\frac{1}{\\sigma_1}, \\ldots, \\frac{1}{\\sigma_n} \\right) \\quad \\text{with some } \\sigma_i \\approx 0 \\] <p>If any \\(\\sigma_i \\to 0\\), then \\(\\frac{1}{\\sigma_i} \\to \\infty\\). So:</p> \\[ \\dot{q} = V \\Sigma^+ U^T \\dot{x} \\] <p>will contain terms like:</p> \\[ \\frac{1}{\\sigma_i} v_i (u_i^T \\dot{x}) \\] <p>These small singular directions correspond to poorly observable or weakly actuated movements (i.e., directions in which the robot has little control or effect). Amplifying these yields huge joint velocities in response to small end-effector demands \u2014 often impossible for the physical system to follow.</p> <p>When the Jacobian becomes near-singular (e.g., robot arm is fully extended, or aligned in a singular configuration), at least one \\(\\sigma_i \\approx 0\\). Then:</p> <ul> <li>Numerical instability in calculating \\(J^+\\)</li> <li>Large errors in joint velocities \\(\\dot{q}\\)</li> <li>Violent, erratic, or unsafe motion if executed on hardware</li> </ul> Proper Treatment: Regularization or Truncation <p>To avoid this:</p> Truncated SVD <p>Set a threshold \\(\\epsilon\\), and discard singular values \\(\\sigma_i &lt; \\epsilon\\):</p> \\[ \\frac{1}{\\sigma_i} := 0 \\quad \\text{if } \\sigma_i &lt; \\epsilon \\] Damped Least Squares (Tikhonov regularization) <p>Use the damped pseudoinverse:</p> \\[ J^+ = V \\left( \\frac{\\Sigma}{\\Sigma^2 + \\lambda^2 I} \\right) U^T \\] <p>Where \\(\\lambda\\) is a small positive constant. This smooths out \\(\\frac{1}{\\sigma_i}\\) near zero:</p> \\[ \\frac{\\sigma_i}{\\sigma_i^2 + \\lambda^2} \\to \\frac{\\sigma_i}{\\lambda^2} \\quad \\text{as } \\sigma_i \\to 0 \\] <p>Which prevents divergence and gives a well-behaved inverse even near singularities.</p> Conclusion <p>Failing to handle small singular values in Jacobian pseudoinversion causes dangerous and unstable joint behavior. It leads to:</p> <ul> <li>Large, unrealistic joint velocities</li> <li>Numerical blowup</li> <li>Physical damage in real robots</li> <li>Total control failure near singularities</li> </ul> <p>Always apply regularization or truncation in inverse kinematics and velocity control.</p>"},{"location":"the_architecture/","title":"THE Architecture","text":"<p>The development of the following architecture was supported by the Tuscany Health Ecosystem (THE) project and it hosted on the sssa-teleoperation GitHub account.</p>"},{"location":"the_architecture/#dry-run","title":"Dry run","text":"<p>Let's try to prepare your host OS for the teleoperation architecture <pre><code>mkdir teleoperation &amp;&amp; cd teleoperation\ngit clone git@github.com:sssa-teleoperation/docker.git\ncd docker &amp;&amp; docker compose up\n</code></pre> If everything set up properly (it will take about 10 minutes) you can try to see what's running on <pre><code>docker exec ros2_tools /rviz2\n</code></pre></p>"},{"location":"tutorial/","title":"Tutorials (Beginner)","text":"<p>At Artificial Hands Area, we use complex devices to pursue our research on Human-Robot Interaction, particularly teleoperation platforms.</p> <p>Our platform is composed of the following:</p> <ul> <li>Robotic arms (Universal Robots)</li> <li>Anthropomorphic grippers (Prensilia Mia Hand)</li> </ul> <p>Then on the operator side, we use a collection of motion capture (mocap) devices:</p> <ul> <li>Wearable IMUs suit (Perception Neuron)</li> <li>Exogloves (Senseglove) \u00a0</li> <li>Reflective markers mocap (Optitrack)</li> </ul> <p>In the end, mocap systems allow us to remap human motions on the robotic platform.</p>"},{"location":"tutorial/#docker","title":"Docker","text":"<p>As you can imagine dealing with all of these components at once is non-trivial and requires a lot of programming. To make our life easier, we decided to develop a comprehensive software architecture, so that you only need to plugin/wear the devices and you're ready to go!</p> <p>Spoiler: We are still developing, thus it's not that easy yet, but it will be!</p> <p>Have you ever heard the citation \"on my computer it works\"? It's very common that you will say those words if you ever share your code with your colleagues. Then to prevent them from replying \"On mine it doesn't\", we decided in our lab not only to share the code but rather the whole pc. How? Virtually. Using Docker containers. </p> <p>To put it simply, a container is a virtual machine which contains the proper operating system configuration that supports your code. When you're ready to share your code, you send the whole container (well actually a copy of it which is called an Image). Your colleague will just turn on the container to have your code integrated into its own system. And so on. So let's break it down!</p> <p></p> <p>The physical pc you're working with has its own (maybe Linux based) operating system (OS), which is called the Host OS. Most likely the Host OS has been installed on your PC by using a physical intallation media, containing a minimal image of the OS itself, let's say it's Ubuntu 22.04. </p> <p>Now maybe one day you find online some cool piece of software, for instance to collect and process a video stream from USB cameras in order to estimate 6D pose of objects in the camera field-of-view. But oh no, you realize that software runs only on Ubuntu 20.04. What do you do? Do you buy another PC? Expensive. Do you downgrade you're own PC? Not so smart. The answer is Docker!</p> <p>If you've Docker installed on your host OS, you can use it to collect a virtual installation media, called an image, from the internet (most likely from DockerHub), and use to create virtual machines (VM) called containers.</p> <p>It's important to undestand some points here:</p> <ul> <li> <p>Whatever modification you apply in the container (the VM), like installing a program in it, it will not affect the image (the original installation media)</p> </li> <li> <p>The containers are completely unrelated to each other, they can communicate in some way, but it's like having a lot of different PCs.</p> </li> <li> <p>If you like, you can freeze the container, most likely after you finished to properly setup the programs you were trying to run, doing a commit of the container. This will produce a new image, which extends the original one with your setups, that you may even upload to the hub and use it later a new virtual installation media (or your colleagues can).</p> </li> </ul> <p>Of course, since the containers are basically virtual machines, they can access any device (processors, GPUs and so on) which are properly operated by the host OS.</p>"},{"location":"tutorial/#linux","title":"Linux","text":"<p>To install docker in Linux, you can follow the install using the apt repository guide. </p> <p>Note: <code>apt</code> is a repository of all packages that you can install on Linux.</p> <p>As you will notice <code>sudo</code> will require your password, which means that docker requires you to log in as an administrator to run any command, like starting the <code>hello-world</code> container. Asking for your password is fine if you need to install a library once using <code>apt</code>, but it's annoying if you need it for any <code>docker</code> command. So, let's say to docker that you can work with containers also as a non-root (i.e., non-administrator) user.</p> <p>For this, we create a new group of users <pre><code>sudo groupadd docker\n</code></pre> and we say that you (the user) are part of that group <pre><code>sudo usermod -aG docker $USER\n</code></pre> Then we say to our operating system that there is a new group of users <pre><code>newgrp docker\n</code></pre> and now starting a container is way simpler <pre><code>docker run hello-world\n</code></pre> The point is that <code>docker</code> is now seeing that you (user) are part of a group named ... docker, so he's happy and it will let you work without asking for your password!</p> <p>Finally, you can set Docker Engine to automatically start on boot whenever you turn on your pc.</p>"},{"location":"tutorial/#windows","title":"Windows","text":"<p>In Windows things may look way easier, but remember, Docker will consume a lot of RAM (not really a lot but at least 8 GB), and we only tested with Windows 11 (you can try with 10, and let us know).</p> <p>Actually, the Docker Engine will run on the Windows Subsystem for Linux (WSL). So you need to run the install WSL command first.</p> <p>Then simply download and install Docker Desktop (it will include the Engine!).</p> <p>Open the application and try from the Windows PowerShell <pre><code>docker run hello-world\n</code></pre></p>"},{"location":"tutorial/#ros","title":"ROS","text":"<p>As we have many devices, our platform requires a lot of specialized code (actually executables) to communicate with each of them, for instance to:</p> <ul> <li>Control the robots (make things move!)</li> <li>Read data from mocap devices (understand how they should move!)</li> </ul> <p>Moreover, how each of these specialized executables can communicate? For instance how the program that reads the posture of the human operator can send the information to the robot, to set its joint positions? Lucky us, we can use the Robot Operating System (ROS).</p> <p>ROS it's not actually an operating system, it's a framework where specialized programs are called nodes. The beauty of nodes is that they can exchange data very easily using ROS communication channels, which are called topics.</p> <p>Moreover, we do not need to write specialized programs for each device we buy. Since ROS it's a standard in robotics research, vendors typically provide ROS driver packages that you can install with <code>apt</code>. So in this way, the communication with the devices is solved. Our job is to develop our own ROS packages, to connect them.</p> <p>Make sure you have the prerequisites before starting with the tutorials on usage and programming of ROS applications.</p> <p>Also, use a proper container to work with the tutorials (extra options are for graphics applications) <pre><code>docker run \\\n    --volume /tmp/.X11-unix:/tmp/.X11-unix \\\n    --volume ${XAUTHORITY:-$HOME/.Xauthority}:/root/.Xauthority \\\n    --device /dev/dri \\\n    --env DISPLAY=$DISPLAY \\\n    -dit --name jazzy osrf/ros:jazzy-desktop\n</code></pre></p> <p>Windows: Make sure you execute the <code>docker run</code> command from a WSL terminal, which you can access by running the <code>wsl</code> command in a Windows PowerShell.</p> <p>If you want to open a terminal to execute commands in the container <pre><code>docker exec -it jazzy bash\n</code></pre> Note: Within the container, you will always be the administrator, so you DON'T need <code>sudo</code> authentication.</p> <p>Note: See in the prerequisites how to use vscode to work within the container.</p> <p>Whenever you want to take a break or resume your work, you can simply stop/start the container <pre><code>docker stop jazzy #to stop it\ndocker start jazzy #to restart it\n</code></pre></p>"},{"location":"tutorial/#prerequisites","title":"Prerequisites","text":""},{"location":"tutorial/#c","title":"C++","text":"<p>As you can imagine you need to write some code to develop ROS packages, which you can do using:</p> <ul> <li>C++</li> <li>Python</li> </ul> <p>C++ it's extremely performant, since it's a compiled language, the code you write is turned into binary instructions before the execution of the program, thanks to a tool which is called ... compiler. However, this comes at the cost of complicated syntax, which means the C++ codes are not easy to understand if you don't have the basics.</p> <p>On the other side, Python codes are way easier to read and write, but they are poorly performant. Indeed the code is not pre-compiled, but's is interpreted during the execution and sent to the machine again as a set of binary instructions. Things are way slower.</p> <p>We strongly suggest to learn the C++ basics for three reasons:</p> <ol> <li>If you understand C++, you will reuse a lot of that knowledge for Python. The opposite doesn't work.</li> <li>At a certain point you will find a ROS package (not yours) that you need to adjust to your will, for your specific application. What if they are written in C++?</li> <li>What if for your application you realize that Python code is not performant enough?</li> </ol> <p>Bonus: To get confident with docker in the meanwhile, we suggest you create a Linux container where you'll work to learn the basics (thus skip the Introduction part of the video tutorial) <pre><code>docker run -d -t --name ubuntu ubuntu #start a basic Linux container\ndocker exec -it ubuntu bash -c 'apt update &amp;&amp; apt install g++ -y' #install the C++ compiler, you will need it!\n</code></pre> Note: See how you can attach vscode to the container to start developing!</p>"},{"location":"tutorial/#cmake","title":"CMake","text":"<p>As you will learn from the video tutorial, you need to manually call the C++ compiler, which is the <code>g++</code> executable, to turn your human-readable code into binary instructions for the machine. Imagine that your project includes many programs to compile. Do you need to call <code>g++</code> manually for each file? No, of course, you can use CMake!</p> <p>CMake is a cross-platform (Windows/Linux) tool that makes the generation of executables easier. No wonder that is the tool you will need to use to compile the code you'll write to form a new ROS package. For this purpose, you will learn to use this tool in the ROS tutorials, but even here a minimum preliminary understanding of CMake is required.  <pre><code>docker exec -it ubuntu bash -c 'apt install cmake -y' #install CMake, you will need it!\n</code></pre> Completing Step 1 and Step 2 of the official tutorial will be enough!</p> <p>Bonus: You can have the official tutorial archive into the container <pre><code>docker cp /path/to/cmake-4.0.0-rc4-tutorial-source.zip ubuntu:/root/tutorial-source.zip #copy to the container\ndocker exec -it ubuntu bash -c 'apt install unzip -y' #needed to extract the archive\ndocker exec -it ubuntu bash -c 'unzip /root/tutorial-source.zip -d /root/tutorial-source' #extract\n</code></pre></p>"},{"location":"tutorial_intermediate/","title":"Tutorials (Intermediate)","text":"<p>Before going on, let's go back to the <code>docker run hello-world</code> command. What <code>docker run</code> does is create a container from the <code>hello-world</code> image. You can create as many containers (completely unrelated) as you want from the same image. </p> <p>Note: We suggest you the vscode docker extension to explore all containers and images on your system.</p> <p>You should also have noticed that <code>docker run</code> will download (or rather <code>pull</code>) the <code>hello-world</code> image from the web (actually from some known repositories, like <code>apt</code> does) if it was not found locally. Try one by one the commands below. <pre><code>docker rmi hello-world #will erase the local image\ndocker pull hello-world #only downloads the latest version of the image.\ndocker run hello-world #start a container with a random fancy name\ndocker run --name pippo hello-world #start a container named pippo\ndocker run --name pluto --rm hello-world #start a container named pippo, automatically remove it on stop (--rm)\ndocker container ls #list all running container\n</code></pre></p>"},{"location":"tutorial_intermediate/#dockerfiles","title":"Dockerfiles","text":"<p>In you went through the ROS tutorial, you probably installed some <code>apt</code> packages to proceed, or maybe you manually downloaded some code from <code>git</code>.</p> <p>The point is, if you loose the container for some reason, will you also loose all the installations you made, all the files you downloaded, within the container? The answer is \"yes\".</p> <p>That's the reason why we use a <code>Dockerfile</code> to keep track of most of the installations. Let's consider the learn the C++ basics example. <pre><code>docker run -d -t --name ubuntu ubuntu #start a basic Linux container: -d sends it in the background (detach), -t keeps it running\ndocker exec -it ubuntu bash -c 'g++ --version' #gives error, g++ is not installed yet\ndocker exec -it ubuntu bash -c 'apt update &amp;&amp; apt install g++ -y' #install the C++ compiler, you will need it!\n</code></pre> We can keep track of the <code>g++</code> installation with a <code>Dockerfile</code>. Create it from vscode and save it in a dedicated folder <pre><code>FROM ubuntu\nRUN apt update &amp;&amp; apt install g++ -y\n</code></pre> How it works? Save it and use it to build a specialized Docker Image <pre><code>docker build -f /path/to/your/folder/Dockerfile -t my-image\n</code></pre> so that if you start a container from the newly created image you will find <code>g++</code> already there <pre><code>docker run -d -t --name my-ubuntu my-image\ndocker exec -it ubuntu bash -c 'g++ --version' #no error, prints the compiler version\ndocker run -it --rm my-image g++ --version #test the new image in a single line\n</code></pre></p>"},{"location":"tutorial_intermediate/#docker-compose","title":"Docker Compose","text":"<p>Docker Containers can be composed together to form a modular architecture. For instance, consider a practical case on our teleoperation platform.</p> <p>You are developing a super cool ROS package which turns a target 6D pose for the robot into target joint angles for the robotic arm. The vendor, Universal Robots in our case, provides us the ROS driver package, which will listen for your joint angle commands (via a <code>ros2 topic</code>) and will take care to send them to the robot.</p> <p>The point is, are you sure that you want to test your new algorithm directly on real (very expensive) robots? Wouldn't you like to see first how the math that you implemented behaves? Maybe you'll find some bugs, so it's a good practice you test your codes on simulated robots first. Remember, simulated arms are free! </p> <p>Here's where modularity helps you! Let's say that your ROS package is installed along with the UR driver into a dedicated container, let's call it drivers. You only need to start a second container which runs the simulator to start debugging. </p> <p>Moreover, imagine that a colleague of yours has a container, let's name it devices, which turns mocap data into target 6D poses for the robots. You can just compose devices and drivers together and the teleoperation system is ready to go!</p> <p>Whenever you're ready to test with real robots, just stop the simulator container and connect the drivers with your real robots.</p>"},{"location":"tutorial_intermediate/#ros","title":"ROS","text":"<p>First, learn how it works in a minimal ROS architecture example.</p> <p>Try to add a custom service (i.e. a container supported by a specific image) to the compose architecture using the Dockerfile <pre><code>version: '2'\n\nservices:\n\u00a0 \u00a0 talker:\n\u00a0 \u00a0 \u00a0 \u00a0 image: osrf/ros:jazzy-desktop\n\u00a0 \u00a0 \u00a0 \u00a0 command: ros2 run demo_nodes_cpp talker\n\u00a0 \u00a0 listener:\n\u00a0 \u00a0 \u00a0 \u00a0 image: osrf/ros:jazzy-desktop\n\u00a0 \u00a0 \u00a0 \u00a0 command: ros2 run demo_nodes_cpp listener\n\u00a0 \u00a0 \u00a0 \u00a0 depends_on: \n            - talker\n\u00a0 \u00a0 my_service:\n\u00a0 \u00a0 \u00a0 \u00a0 build:\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 dockerfile: /path/to/your/folder/Dockerfile\n\u00a0 \u00a0 \u00a0 \u00a0 command: g++ --version\n</code></pre> <pre><code>docker compose build my_service #build only my_service\ndocker compose up my_service #run only my_service\n</code></pre> or  <pre><code>docker compose build\ndocker compose up\n</code></pre> Note: Docker will take a lot of memory (disk) to store images and containers. Periodically remove unused images. Moreover clear the builder cache with <code>docker builder prune</code>. Cleaning the cache means that new builds will start almost from scratch, which means they eill take more time.</p>"}]}